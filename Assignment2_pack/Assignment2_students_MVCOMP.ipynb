{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eVey53yXnDE"
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "## General information\n",
    "\n",
    "This assignment has two problems:\n",
    " - 1: Linear Discriminat Analysis\n",
    " - 2: Quadratic Discriminat Analysis\n",
    "\n",
    "Utilize the designated cells within this notebook to complete the exercises. As for the Python exercises:\n",
    "- Refrain from altering the provided code; simply fill in the missing portions as indicated.\n",
    "- Do not use any additional libraries beyond those already included in the code (e.g., NumPy library).\n",
    "- Make sure that the output of all code cells is visible in your submitted notebook. **The evaluator is NOT expected to execute your code before grading your submission.**\n",
    "- Some problems include automatic checks (*assertions*) to verify basic aspects of your solution. However, passing these assertions does not guarantee that your solution is entirely correct. The final evaluation will always be determined by the evaluator.\n",
    "- Avoid the use of for loops by using NumPy vectorized operations whenever possible.\n",
    "   \n",
    "Please identify the authors of this assignment in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM05fvVqQA-R"
   },
   "source": [
    "## Identification\n",
    "\n",
    "* **Name: Liu Cong**\n",
    "* **Student Number:**\n",
    "\n",
    "* **Name: Ulloa Ferrer Leonardo**\n",
    "* **Student Number:**\n",
    "\n",
    "* **Name:**\n",
    "* **Student Number:**\n",
    "---\n",
    "\n",
    "**Note:** This work is to be done in group of up to **3** elements. Use this notebook to answer all the questions. At the end of the work, you should **upload** the **notebook** and a **pdf file** with a printout of the notebook with all the results in the **moodle** platform.\n",
    "To generate the pdf file we have first to covert the notebook to html using the command `!jupyter nbconvert --to html \"ML_project2.ipynb\"`, then open the html file and printout to PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAFvjQVHQBLt"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "For this assignment, we will consider the task of predicting the quality of red wine (rated on an integer scale from 0 to 5) based on 11 chemical properties, such as pH, alcohol content, residual sugar, etc. This dataset was originally published in:\n",
    "\n",
    "Cortez, Paulo, et al. [\"Modeling wine preferences by data mining from physicochemical properties.\"](https://https://www.sciencedirect.com/science/article/abs/pii/S0167923609001377) Decision support systems 47.4 (2009): 547-553.\n",
    "\n",
    "Since quality is a discrete and ordinal attribute, this problem could be framed as either a regression or classification task. For this assignment, we will treat it as a classification problem. Specifically, we have a **6-class classification dataset** ($y \\in \\{0, 1, \\dots, 5\\}$) where each **feature vector is 11-dimensional** ($\\mathbf{x} \\in \\mathbb{R}^{11}$).\n",
    "\n",
    "In the cell below, we load and prepare the data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lvDtT4_8MkMX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A training example:\n",
      "fixed acidity            8.60000\n",
      "volatile acidity         0.22000\n",
      "citric acid              0.36000\n",
      "residual sugar           1.90000\n",
      "chlorides                0.06400\n",
      "free sulfur dioxide     53.00000\n",
      "total sulfur dioxide    77.00000\n",
      "density                  0.99604\n",
      "pH                       3.47000\n",
      "sulphates                0.87000\n",
      "alcohol                 11.00000\n",
      "quality                  4.00000\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "A test example:\n",
      "fixed acidity            7.7000\n",
      "volatile acidity         0.5600\n",
      "citric acid              0.0800\n",
      "residual sugar           2.5000\n",
      "chlorides                0.1140\n",
      "free sulfur dioxide     14.0000\n",
      "total sulfur dioxide    46.0000\n",
      "density                  0.9971\n",
      "pH                       3.2400\n",
      "sulphates                0.6600\n",
      "alcohol                  9.6000\n",
      "quality                  3.0000\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "X_train shape: (1119, 11)\n",
      "X_test shape: (480, 11)\n",
      "y_train shape: (1119,)\n",
      "y_test shape: (480,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"winequality_train.csv\")\n",
    "print(\"A training example:\")\n",
    "print(train_data.iloc[0])\n",
    "print()\n",
    "test_data = pd.read_csv(\"winequality_test.csv\")\n",
    "print(\"A test example:\")\n",
    "print(test_data.iloc[0])\n",
    "print()\n",
    "\n",
    "X_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data.iloc[:, -1].values\n",
    "X_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data.iloc[:, -1].values\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl7wtbg5AnHk"
   },
   "source": [
    "An important **preprocessing step** for multi-dimensional continuous data is to ensure all features have **zero mean** and **unit variance**. In the code below, we transform the data to achieve this.\n",
    "\n",
    "**When normalizing the test data, we reuse the mean and standard deviation from the training data**, rather than recalculating them. This ensures a fair evaluation, since we want to classify new examples without assuming any prior knowledge about their distribution beyond what was learned during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xnmjozR85Jpj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data statistics before normalization:\n",
      "  * mean: [ 8.30956211  0.53313226  0.27025022  2.54830206  0.08771135 15.9204647\n",
      " 46.96648794  0.996778    3.31427167  0.65882038 10.41733691]\n",
      "  * std: [1.71313271e+00 1.81940308e-01 1.95404143e-01 1.42709225e+00\n",
      " 4.71218617e-02 1.02685749e+01 3.30219278e+01 1.83946303e-03\n",
      " 1.53911124e-01 1.72165005e-01 1.05927763e+00]\n",
      "\n",
      "Test data statistics before normalization:\n",
      "  * mean: [ 8.343125    0.5154375   0.27266667  2.51666667  0.08689583 15.76875\n",
      " 45.30520833  0.99667367  3.30375     0.65658333 10.43614583]\n",
      "  * std: [1.80263540e+00 1.71324851e-01 1.93172994e-01 1.36730930e+00\n",
      " 4.68790285e-02 1.08825004e+01 3.25340058e+01 1.99070295e-03\n",
      " 1.55079617e-01 1.62948079e-01 1.07920724e+00]\n",
      "\n",
      "Training data statistics after normalization:\n",
      "  * mean: [ 5.42907988e-16 -2.34148913e-16  1.65094827e-16 -6.66729109e-17\n",
      "  3.41301806e-16  7.93725129e-18  1.58745026e-17 -4.02418641e-14\n",
      " -8.25474134e-16 -4.42898622e-16  1.17471319e-16]\n",
      "  * std: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Test data statistics after normalization:\n",
      "  * mean: [ 0.01959153 -0.09725586  0.01236639 -0.02216773 -0.01730653 -0.01477466\n",
      " -0.05030838 -0.05671848 -0.06836199 -0.01299359  0.01775637]\n",
      "  * std: [1.05224505 0.94165418 0.98858187 0.95810856 0.9948467  1.05978683\n",
      " 0.9852243  1.0822196  1.007592   0.94646458 1.01881434]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data statistics before normalization:\")\n",
    "print(\"  * mean:\", X_train.mean(axis=0))\n",
    "print(\"  * std:\", X_train.std(axis=0))\n",
    "print()\n",
    "print(\"Test data statistics before normalization:\")\n",
    "print(\"  * mean:\", X_test.mean(axis=0))\n",
    "print(\"  * std:\", X_test.std(axis=0))\n",
    "print()\n",
    "\n",
    "train_mean = X_train.mean(axis=0)\n",
    "train_std = X_train.std(axis=0)\n",
    "X_train = (X_train - train_mean) / train_std\n",
    "X_test = (X_test - train_mean) / train_std\n",
    "\n",
    "print(\"Training data statistics after normalization:\")\n",
    "print(\"  * mean:\", X_train.mean(axis=0))\n",
    "print(\"  * std:\", X_train.std(axis=0))\n",
    "print()\n",
    "print(\"Test data statistics after normalization:\")\n",
    "print(\"  * mean:\", X_test.mean(axis=0))\n",
    "print(\"  * std:\", X_test.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szaZLcuDZQp7"
   },
   "source": [
    "## Problem 1: Generative Classifiers (Linear Discriminant Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpCEelC1Z9X5"
   },
   "source": [
    "Consider a classifier that predicts the class label $\\widehat{y}$ for an observed feature vector $\\mathbf{x}$ using the *maximum a posteriori* (MAP) classification rule:\n",
    "\n",
    "$$\n",
    "\\widehat{y} = \\arg\\max_y p(y \\mid \\mathbf{x}).\n",
    "$$\n",
    "\n",
    "Assume the following:\n",
    "1. The distribution of $\\mathbf{x} \\mid y$ is Gaussian.\n",
    "2. The covariance matrix is shared by all the classes.\n",
    "\n",
    "In the cell below, you have the skeleton of a `LDAClassifier` class that you will complete throughout this exercise to implement this classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gUX6cTxY2CS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def pda_multivariate_normal(mean: np.ndarray, cov: np.ndarray, x: np.ndarray):\n",
    "    # I thought that why shouldn't use multivariate normal and made this, and then saw \n",
    "    # the multivariate normal in the template, but i had already done this.\n",
    "    F = mean.shape[0]\n",
    "    temp = x - mean\n",
    "    det_cov = np.linalg.det(cov)\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    diagonal = np.einsum('ni,ij,nj->n', temp, inv_cov, temp)\n",
    "    prefactor = 1 / np.sqrt((2 * np.pi)**F * det_cov)\n",
    "    return prefactor * np.exp(-0.5 * diagonal)\n",
    "\n",
    "class LDAClassifier:\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Estimate the parameters of the classifier from the training data.\n",
    "\n",
    "        Parameters:\n",
    "        X: np.ndarray of shape (num_examples, num_features)\n",
    "            The input data (features).\n",
    "        y: np.ndarray of shape (num_examples,)\n",
    "            The corresponding labels (target values).\n",
    "        \"\"\"\n",
    "        # ToDo: Exercise 1.2\n",
    "        # **Replace `pass` with your code**\n",
    "        num_examples, num_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        num_classes = len(self.classes)\n",
    "\n",
    "        self.means = np.zeros((num_classes, num_features))\n",
    "        self.priors = np.zeros(num_classes)\n",
    "\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            X_cls = X[y == cls]\n",
    "            self.means[idx] = X_cls.mean(axis=0)\n",
    "            self.priors[idx] = X_cls.shape[0] / X.shape[0]\n",
    "\n",
    "        cov_matrix = np.zeros((num_features, num_features))\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            X_cls = X[y == cls]\n",
    "            cov_matrix += np.dot((X_cls - self.means[idx]).T, (X_cls - self.means[idx]))\n",
    "        self.covariance = cov_matrix / (X.shape[0] - num_classes)\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class probabilities for the given input data.\n",
    "\n",
    "        Parameters:\n",
    "        X: np.ndarray of shape (num_examples, num_features)\n",
    "            The input data (features).\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray of shape (num_examples, num_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        # ToDo: Exercise 1.3\n",
    "        # **Replace `pass` with your code**\n",
    "        num_samples = X.shape[0]\n",
    "        num_classes = len(self.classes)\n",
    "        \n",
    "        probs = np.zeros((num_samples, num_classes))\n",
    "        \n",
    "\n",
    "\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            mean = self.means[idx]\n",
    "            cov = self.covariance\n",
    "            likelihood = pda_multivariate_normal(mean,cov, X)\n",
    "            probs[:, idx] = likelihood * self.priors[idx]\n",
    "        \n",
    "        probs_sum = probs.sum(axis=1, keepdims=True)\n",
    "        probs = probs / probs_sum\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class labels for the input data using the estimated model parameters.\n",
    "\n",
    "        Parameters:\n",
    "        X: np.ndarray of shape (num_examples, num_features)\n",
    "            The input data (features) for which predictions are needed.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray of shape (num_examples,)\n",
    "            The predicted class labels.\n",
    "        \"\"\"\n",
    "        # ToDo: Exercise 1.4\n",
    "        # **Replace `pass` with your code**\n",
    "        probs = self.predict_proba(X)\n",
    "        \n",
    "        \n",
    "        predictions = np.argmax(probs, axis=1)\n",
    "        return self.classes[predictions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVHMijtxYpoE"
   },
   "source": [
    "### 1.1\n",
    "Based on the assumptions given before, **identify all the parameters** in the model and **write down the expressions for their maximum likelihood estimates**. You do not need to show the derivation of the expressions, just the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiJf1aP7cZkT"
   },
   "source": [
    "**Notation:**\n",
    "- $N_i$: sample size in class $c_i$\n",
    "- $N$: sample size\n",
    "- $K$: number of classes\n",
    "\n",
    "\n",
    "**Prior of class $c_i$**:\n",
    "\n",
    "$\n",
    "\\hat{P}(c_i) = \\frac{N_i}{N}\n",
    "$\n",
    "\n",
    "**Mean of class $c_i$**:\n",
    "\n",
    "$\n",
    "\\hat{\\mu}_i = \\frac{1}{N_i - 1} \\sum_{i:y_i = y}X_i\n",
    "$\n",
    "\n",
    "**Covariance Matrix of $c_i$**:\n",
    "\n",
    "$\n",
    "\\hat{\\sum}_i = \\frac{1}{N_i - 1} \\sum_{i = 1}^{N}(X_i - \\hat{\\mu}_{y_i})(X_i - \\hat{\\mu}_{y_i})^T\n",
    "$\n",
    "\n",
    "**Pooled covariance matrix $c_i$**:\n",
    "\n",
    "$\n",
    "\\hat{\\sum} = \\frac{1}{N - K} \\sum_{i = 1}^{K}(N_i - 1)\\hat{\\sum}_i\n",
    "$\n",
    "\n",
    "$\n",
    "= \\frac{1}{N - K} \\sum_{i = 1}^{K}(X_i - \\hat{\\mu}_{y_i})(X_i - \\hat{\\mu}_{y_i})^T\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf85q0JTdhpM"
   },
   "source": [
    "### 1.2\n",
    "In this exercise, you should write the code for the `fit` method of this classifier. This method should **estimate all model parameters** using the data provided as arguments. Specifically:\n",
    "\n",
    "- `X`: A NumPy array of shape `(num_examples, num_features)` containing the training input examples $\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_n$.\n",
    "- `y`: A NumPy array of shape `(num_examples,)` containing the corresponding labels $y_1, y_2, \\dots, y_n$.\n",
    "\n",
    "The model parameters should be saved as class attributes, so they can be used later during prediction.\n",
    "\n",
    "After implementing the function, run the cell below to make sure that all the assertions pass and that the model parameter names and values are printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OXq8kE-PZgzF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier attributes:\n",
      "  * classes, shape (6,): [0 1 2 3 4 5]\n",
      "  * means, shape (6, 11): [[ 1.37106912e-01  2.00725764e+00 -4.22060885e-01  1.25763224e-01\n",
      "   8.43198752e-01 -4.25074483e-01 -6.24831922e-01  4.61367497e-01\n",
      "   4.34272965e-01 -5.54625151e-01 -4.35939868e-01]\n",
      " [-2.69879785e-01  6.80509915e-01 -3.01228692e-01  5.76371290e-02\n",
      "   1.74129734e-01 -2.46536238e-01 -2.00871210e-01 -1.57623531e-01\n",
      "   2.66427180e-01 -2.57752328e-01 -2.01241142e-01]\n",
      " [-6.28732712e-02  2.80444275e-01 -1.28167508e-01  1.39499189e-02\n",
      "   8.84356273e-02  1.03727345e-01  3.17583390e-01  2.08867168e-01\n",
      "  -6.18446834e-02 -2.18073674e-01 -5.01012554e-01]\n",
      " [ 8.15345524e-04 -1.75140616e-01  5.84670637e-03 -6.61630507e-02\n",
      "  -4.65407032e-02 -2.28261122e-02 -1.98174787e-01 -8.46028330e-02\n",
      "   7.80116953e-02  1.06442906e-01  2.14973258e-01]\n",
      " [ 2.43136358e-01 -6.90115339e-01  4.72653602e-01  1.26863397e-01\n",
      "  -2.32386401e-01 -1.77496745e-01 -3.57332901e-01 -4.13927324e-01\n",
      "  -8.47228373e-02  4.78677468e-01  1.04271341e+00]\n",
      " [ 4.27348421e-01 -5.76007202e-01  7.62094604e-01  1.23816764e-01\n",
      "  -3.65251898e-01 -2.68177237e-01 -4.48181625e-01 -4.84107698e-01\n",
      "  -4.93390835e-01  6.31252702e-01  1.38395863e+00]]\n",
      "  * priors, shape (6,): [0.0080429  0.03217158 0.43431635 0.39142091 0.1233244  0.01072386]\n",
      "  * covariance, shape (11, 11): [[ 0.99185791 -0.2121593   0.6407643   0.1190726   0.11123889 -0.13836573\n",
      "  -0.08337088  0.6787589  -0.67692057  0.13942941 -0.0976629 ]\n",
      " [-0.2121593   0.84878973 -0.47931437 -0.00503167  0.01763438 -0.0356702\n",
      "   0.00119635 -0.05551758  0.21245081 -0.17773231 -0.02534906]\n",
      " [ 0.6407643  -0.47931437  0.95986782  0.16788067  0.24222922 -0.04259647\n",
      "   0.08889401  0.41062754 -0.52664782  0.25618725  0.01047294]\n",
      " [ 0.1190726  -0.00503167  0.16788067  1.001187    0.0647507   0.15263664\n",
      "   0.16655545  0.38013492 -0.09036379  0.00879145  0.04309229]\n",
      " [ 0.11123889  0.01763438  0.24222922  0.0647507   0.98625924 -0.00920229\n",
      "   0.01441464  0.16619225 -0.26742823  0.39440265 -0.13816211]\n",
      " [-0.13836573 -0.0356702  -0.04259647  0.15263664 -0.00920229  0.99237891\n",
      "   0.64314801 -0.04786564  0.05826412  0.06942813 -0.04390487]\n",
      " [-0.08337088  0.00119635  0.08889401  0.16655545  0.01441464  0.64314801\n",
      "   0.92343509  0.01647462 -0.06328205  0.09085758 -0.09634875]\n",
      " [ 0.6787589  -0.05551758  0.41062754  0.38013492  0.16619225 -0.04786564\n",
      "   0.01647462  0.95722923 -0.32980707  0.18221407 -0.36132685]\n",
      " [-0.67692057  0.21245081 -0.52664782 -0.09036379 -0.26742823  0.05826412\n",
      "  -0.06328205 -0.32980707  0.99399017 -0.18901265  0.19996288]\n",
      " [ 0.13942941 -0.17773231  0.25618725  0.00879145  0.39440265  0.06942813\n",
      "   0.09085758  0.18221407 -0.18901265  0.94282387 -0.01806321]\n",
      " [-0.0976629  -0.02534906  0.01047294  0.04309229 -0.13816211 -0.04390487\n",
      "  -0.09634875 -0.36132685  0.19996288 -0.01806321  0.71929272]]\n"
     ]
    }
   ],
   "source": [
    "# instantiate the classifier and train it\n",
    "lda_clf = LDAClassifier()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "\n",
    "assert lda_clf.__dict__.keys(), (\"`fit` method not implemented yet or not \"\n",
    "\"creating the class attributes.\")\n",
    "print(\"Classifier attributes:\")\n",
    "for attr, value in lda_clf.__dict__.items():\n",
    "    shape = f\", shape {value.shape}\" if hasattr(value, \"shape\") else \"\"\n",
    "    print(f\"  * {attr}{shape}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSLu9JeJbMBS"
   },
   "source": [
    "### 1.3\n",
    "Implement the `predict_proba` method of the `LDAClassifier` class. This method should use the model parameters estimated during the `fit` method to **predict the probabilities of each class** for new input data. Specifically, the input is:\n",
    "\n",
    "- `X`: A NumPy array of shape `(num_examples, num_features)` containing the input examples $\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_n$ for which predictions are needed.\n",
    "\n",
    "The method should return a NumPy array of shape `(num_examples, num_classes)` containing the predicted probabilities $p(y=0 \\mid \\mathbf{x}_i), p(y=1 \\mid \\mathbf{x}_i), \\dots, p(y=C-1 \\mid \\mathbf{x}_i)$, for $i \\in \\{1, 2, \\dots, n\\}$.\n",
    "\n",
    "After implementing the function, run the cell below to make sure that all the assertions pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S-7e3TzWcOnH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your `predict_proba` looks good! 🚀\n"
     ]
    }
   ],
   "source": [
    "# instantiate the classifier\n",
    "# (we need to do this again because you probably changed the code of LDAClassifier\n",
    "# after you ran the previous cell)\n",
    "lda_clf = LDAClassifier()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the class probabilities for the training data\n",
    "probs = lda_clf.predict_proba(X_train)\n",
    "\n",
    "assert probs is not None, (\"`predict_proba` method not implemented yet or \"\n",
    "\"not returning a valid array.\")\n",
    "assert probs.shape == (len(X_train), 6), (\"`predict_proba` output should \"\n",
    "\"have shape (num_examples, num_classes).\")\n",
    "assert np.all((probs >= 0) * (probs <= 1)), (\"`predict_proba` output should be \"\n",
    "\"probabilities.\")\n",
    "assert np.allclose(probs.sum(axis=1), 1), (\"`predict_proba` output should be a \"\n",
    "\"(proper) probability distribution.\")\n",
    "print(\"Your `predict_proba` looks good! 🚀\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4LLeAaQgLzQ"
   },
   "source": [
    "### 1.4\n",
    "Implement the `predict` method of the `LDAClassifier` class. This method should **predict the class labels** for new input data, by applying the MAP rule. Specifically, the input is:\n",
    "\n",
    "- `X`: A NumPy array of shape `(num_examples, num_features)` containing the input examples $\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_n$ for which predictions are needed.\n",
    "\n",
    "The method should return a NumPy array of shape `(num_examples,)` containing the predicted class labels $\\widehat{y}_1, \\widehat{y}_2, \\dots, \\widehat{y}_n$.\n",
    "\n",
    "After implementing the function, run the cell below to make sure that all the assertions pass and that a summary of the model predictions is printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pp4b2ax3eoYS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your classifier predicted:\n",
      "  * 8 training examples in class 0.\n",
      "  * 1 training examples in class 1.\n",
      "  * 547 training examples in class 2.\n",
      "  * 453 training examples in class 3.\n",
      "  * 109 training examples in class 4.\n",
      "  * 1 training examples in class 5.\n",
      "\n",
      "Your classifier predicted:\n",
      "  * 3 test examples in class 0.\n",
      "  * 0 test examples in class 1.\n",
      "  * 227 test examples in class 2.\n",
      "  * 192 test examples in class 3.\n",
      "  * 58 test examples in class 4.\n",
      "  * 0 test examples in class 5.\n"
     ]
    }
   ],
   "source": [
    "# instantiate the classifier\n",
    "# (we need to do this again because you probably changed the code of LDAClassifier\n",
    "# after you ran the previous cell)\n",
    "lda_clf = LDAClassifier()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the class labels for the training data\n",
    "y_train_pred = lda_clf.predict(X_train)\n",
    "assert y_train_pred is not None, (\"`predict` method not implemented yet or not returning \"\n",
    "\"any predictions.\")\n",
    "assert len(y_train_pred) == len(X_train), (\"You should have one predicted \"\n",
    "\"label for each input example.\")\n",
    "print(\"Your classifier predicted:\")\n",
    "for j in range(6):\n",
    "    print(f\"  * {(y_train_pred == j).sum()} training examples in class {j}.\")\n",
    "print()\n",
    "\n",
    "# predict the class labels for the test data\n",
    "y_test_pred = lda_clf.predict(X_test)\n",
    "assert y_test_pred is not None, (\"`predict` method not implemented yet or not returning \"\n",
    "\"any predictions.\")\n",
    "assert len(y_test_pred) == len(X_test), (\"You should have one predicted \"\n",
    "\"label for each input example.\")\n",
    "print(\"Your classifier predicted:\")\n",
    "for j in range(6):\n",
    "    print(f\"  * {(y_test_pred == j).sum()} test examples in class {j}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6465-BowhHoB"
   },
   "source": [
    "### 1.5\n",
    "Complete the code of the function `compute_accuracy`, which **computes the accuracy** of a given set of predictions when compared to the ground-truth labels. This function will be used to compute the training and test accuracies of our `LDAClassifier`.\n",
    "\n",
    "After implementing the function, run the cell below to make sure that all the assertions pass and that the values of the training and test accuracies are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OFq5rhpzhG5s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.624\n",
      "Test accuracy: 0.565\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the classifier.\n",
    "\n",
    "    Parameters:\n",
    "    y_true: np.ndarray of shape (num_examples,)\n",
    "        The true class labels.\n",
    "    y_pred: np.ndarray of shape (num_examples,)\n",
    "        The predicted class labels.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The accuracy of the classifier.\n",
    "    \"\"\"\n",
    "    # ToDo:\n",
    "    # **Replace `pass` with your code**\n",
    "    num_correct = np.sum(y_true == y_pred)\n",
    "    \n",
    "    accuracy = num_correct / len(y_true)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# compute the training accuracy\n",
    "train_accuracy = compute_accuracy(y_train, y_train_pred)\n",
    "assert train_accuracy is not None, (\"`compute_accuracy` not implemented yet or \"\n",
    "\"not returning a valid float.\")\n",
    "print(f\"Training accuracy: {train_accuracy:.3f}\")\n",
    "\n",
    "# compute the test accuracy\n",
    "test_accuracy = compute_accuracy(y_test, y_test_pred)\n",
    "assert test_accuracy is not None, (\"`compute_accuracy` not implemented yet or \"\n",
    "\"not returning a valid float.\")\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCBIKZOiB4_N"
   },
   "source": [
    "### 1.6\n",
    "Explain why normalizing features to have zero mean and unit variance is an important preprocessing step **for this classifier**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nbSsfDoCSCv"
   },
   "source": [
    "LDA assumes that the features within each category follow a Gaussian distribution and that all categories share the same covariance matrix. Normalizing the training data helps align the features to this assumption by standardizing their scales and variances, thereby reducing errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Xz8j4Ulnbr"
   },
   "source": [
    "## Problem 2: Quadratic Discriminant Analysis (QDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now repeat the analysis performed on the previous exercise (items 1.2 to 1.5), but now using the QDA model. At the end, compare the performance of both methods and define which one would you choose to deploy. In the cell below, you have the skeleton of a `QDAClassifier` class that you will complete throughout this exercise to implement this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class QDAClassifier:\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Estimate the parameters of the classifier from the training data.\n",
    "\n",
    "        Parameters:\n",
    "        X: np.ndarray of shape (num_examples, num_features)\n",
    "            The input data (features).\n",
    "        y: np.ndarray of shape (num_examples,)\n",
    "            The corresponding labels (target values).\n",
    "        \"\"\"\n",
    "        # ToDo:\n",
    "        num_examples, num_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        num_classes = len(self.classes)\n",
    "\n",
    "        self.means = np.zeros((num_classes, num_features))\n",
    "        self.priors = np.zeros(num_classes)\n",
    "\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            X_cls = X[y == cls]\n",
    "            self.means[idx] = X_cls.mean(axis=0)\n",
    "            self.priors[idx] = X_cls.shape[0] / X.shape[0]\n",
    "\n",
    "        self.cov_matrix = np.zeros((num_features,num_features,num_classes))\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            X_cls = X[y == cls]\n",
    "            self.cov_matrix[:,:,idx] = np.dot((X_cls - self.means[idx]).T, (X_cls - self.means[idx]))/(X_cls.shape[0] - 1)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class probabilities for the given input data.\n",
    "\n",
    "        Parameters:\n",
    "        X: np.ndarray of shape (num_examples, num_features)\n",
    "            The input data (features).\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray of shape (num_examples, num_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        # ToDo:\n",
    "        num_samples = X.shape[0]\n",
    "        num_classes = len(self.classes)\n",
    "        \n",
    "        probs = np.zeros((num_samples, num_classes))\n",
    "\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            mean = self.means[idx]\n",
    "            cov = self.cov_matrix[:,:,idx]\n",
    "            print('X',X.shape)\n",
    "            print('cov',cov.shape)\n",
    "            print('mean',mean.shape)\n",
    "            likelihood = multivariate_normal(X, mean,cov)\n",
    "            probs[:, idx] = likelihood * self.priors[idx]\n",
    "        \n",
    "        probs_sum = probs.sum(axis=1, keepdims=True)\n",
    "        print('probs',probs)\n",
    "        probs = probs / probs_sum\n",
    "        print('probs_sum',(probs_sum))\n",
    "        print('probs',probs)\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class labels for the input data using the estimated model parameters.\n",
    "\n",
    "        Parameters:\n",
    "        X: np.ndarray of shape (num_examples, num_features)\n",
    "            The input data (features) for which predictions are needed.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray of shape (num_examples,)\n",
    "            The predicted class labels.\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(X)\n",
    "        \n",
    "        \n",
    "        predictions = np.argmax(probs, axis=1)\n",
    "        return self.classes[predictions]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "What is the difference between the estimated parameters of LDA and QDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "\n",
    "Write your fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier attributes:\n",
      "  * classes, shape (6,): [0 1 2 3 4 5]\n",
      "  * means, shape (6, 11): [[ 1.37106912e-01  2.00725764e+00 -4.22060885e-01  1.25763224e-01\n",
      "   8.43198752e-01 -4.25074483e-01 -6.24831922e-01  4.61367497e-01\n",
      "   4.34272965e-01 -5.54625151e-01 -4.35939868e-01]\n",
      " [-2.69879785e-01  6.80509915e-01 -3.01228692e-01  5.76371290e-02\n",
      "   1.74129734e-01 -2.46536238e-01 -2.00871210e-01 -1.57623531e-01\n",
      "   2.66427180e-01 -2.57752328e-01 -2.01241142e-01]\n",
      " [-6.28732712e-02  2.80444275e-01 -1.28167508e-01  1.39499189e-02\n",
      "   8.84356273e-02  1.03727345e-01  3.17583390e-01  2.08867168e-01\n",
      "  -6.18446834e-02 -2.18073674e-01 -5.01012554e-01]\n",
      " [ 8.15345524e-04 -1.75140616e-01  5.84670637e-03 -6.61630507e-02\n",
      "  -4.65407032e-02 -2.28261122e-02 -1.98174787e-01 -8.46028330e-02\n",
      "   7.80116953e-02  1.06442906e-01  2.14973258e-01]\n",
      " [ 2.43136358e-01 -6.90115339e-01  4.72653602e-01  1.26863397e-01\n",
      "  -2.32386401e-01 -1.77496745e-01 -3.57332901e-01 -4.13927324e-01\n",
      "  -8.47228373e-02  4.78677468e-01  1.04271341e+00]\n",
      " [ 4.27348421e-01 -5.76007202e-01  7.62094604e-01  1.23816764e-01\n",
      "  -3.65251898e-01 -2.68177237e-01 -4.48181625e-01 -4.84107698e-01\n",
      "  -4.93390835e-01  6.31252702e-01  1.38395863e+00]]\n",
      "  * priors, shape (6,): [0.0080429  0.03217158 0.43431635 0.39142091 0.1233244  0.01072386]\n",
      "  * cov_matrix, shape (11, 11, 6): [[[ 1.07170929e+00  9.74988946e-01  8.12067498e-01  1.08797495e+00\n",
      "    1.29162832e+00  1.36260832e+00]\n",
      "  [-1.31635420e+00 -2.89328399e-01 -1.47092297e-01 -2.61002910e-01\n",
      "   -1.80715142e-01 -4.83632596e-01]\n",
      "  [ 1.33153641e+00  5.47152635e-01  5.02073581e-01  7.01793065e-01\n",
      "    8.85206132e-01  1.08232147e+00]\n",
      "  [-3.68952256e-01  1.33000222e-02  1.23952295e-01  8.89258926e-02\n",
      "    2.17665605e-01  5.65114450e-01]\n",
      "  [-8.48205288e-02  3.28604216e-01  8.09409547e-02  1.21163377e-01\n",
      "    1.37806054e-01  1.72919387e-01]\n",
      "  [ 2.40726415e-01  2.61229272e-01 -1.00867645e-01 -2.22244297e-01\n",
      "   -1.19563922e-01 -2.40733593e-01]\n",
      "  [ 2.28400523e-01  9.52701754e-02 -5.32533888e-02 -1.10038917e-01\n",
      "   -1.48524828e-01 -3.35513278e-01]\n",
      "  [ 9.11954585e-01  6.78147596e-01  4.92283383e-01  7.53568596e-01\n",
      "    1.06037424e+00  1.00815156e+00]\n",
      "  [-5.05576913e-01 -7.95904753e-01 -5.59135572e-01 -7.45055153e-01\n",
      "   -8.20020120e-01 -1.12715427e+00]\n",
      "  [ 4.51643234e-01  3.52655350e-01  7.89592317e-02  1.87817554e-01\n",
      "    1.61718701e-01 -2.99828331e-01]\n",
      "  [-5.28482216e-01 -3.45468939e-01  1.26994275e-02 -1.06422230e-01\n",
      "   -3.56420878e-01 -2.91143570e-01]]\n",
      "\n",
      " [[-1.31635420e+00 -2.89328399e-01 -1.47092297e-01 -2.61002910e-01\n",
      "   -1.80715142e-01 -4.83632596e-01]\n",
      "  [ 3.66421183e+00  1.55471736e+00  8.84301126e-01  7.66352544e-01\n",
      "    6.39714278e-01  8.68291491e-01]\n",
      "  [-1.89347646e+00 -6.62249078e-01 -4.12556003e-01 -5.34441228e-01\n",
      "   -4.05755444e-01 -5.38308337e-01]\n",
      "  [ 4.85597798e-01 -5.50270811e-01 -2.59178332e-02  2.93380524e-02\n",
      "    7.52100827e-02 -7.09008382e-02]\n",
      "  [-5.16838037e-01 -5.37350761e-02  6.18559785e-03  3.81289307e-02\n",
      "    5.29818489e-02 -1.16216155e-01]\n",
      "  [-9.63905420e-01 -7.28286927e-02 -3.71377780e-02 -1.05560050e-02\n",
      "   -4.75370240e-02 -2.75737531e-02]\n",
      "  [-5.99823265e-01 -1.67672711e-01  9.44219675e-03  1.76520666e-02\n",
      "   -2.91267216e-02  3.35965084e-01]\n",
      "  [-1.39873695e+00 -5.40198848e-02 -9.65177990e-02 -2.26459862e-02\n",
      "    9.12758417e-02 -4.09803651e-01]\n",
      "  [ 1.20197012e+00  4.48815438e-01  1.33728109e-01  2.37989632e-01\n",
      "    2.43645634e-01  8.08581851e-01]\n",
      "  [-1.11696382e+00 -3.38776317e-01 -1.70736139e-01 -1.63258887e-01\n",
      "   -1.64933321e-01 -2.51043868e-02]\n",
      "  [ 1.13427852e+00  4.45427967e-02 -1.28405992e-02 -8.35837650e-02\n",
      "   -1.75991551e-02  5.74376952e-01]]\n",
      "\n",
      " [[ 1.33153641e+00  5.47152635e-01  5.02073581e-01  7.01793065e-01\n",
      "    8.85206132e-01  1.08232147e+00]\n",
      "  [-1.89347646e+00 -6.62249078e-01 -4.12556003e-01 -5.34441228e-01\n",
      "   -4.05755444e-01 -5.38308337e-01]\n",
      "  [ 1.76832189e+00  1.25728374e+00  8.47390668e-01  1.01073818e+00\n",
      "    1.06228591e+00  1.08828610e+00]\n",
      "  [-4.66607536e-01  3.93897176e-01  1.44346513e-01  1.41550886e-01\n",
      "    2.94432476e-01  4.17691250e-01]\n",
      "  [ 1.61396857e-02  1.34365534e+00  2.65544975e-01  1.57220047e-01\n",
      "    1.67888385e-01  1.77171788e-01]\n",
      "  [ 3.15914237e-01  3.90021776e-01  3.39372062e-02 -1.68767155e-01\n",
      "   -1.75166636e-02 -3.54223652e-01]\n",
      "  [ 3.46499997e-01  3.68591424e-01  1.93825843e-01 -2.71784410e-02\n",
      "    3.57462365e-02 -3.41768540e-01]\n",
      "  [ 1.13866195e+00  5.00645453e-01  3.24479172e-01  4.09677989e-01\n",
      "    6.12378692e-01  9.18091819e-01]\n",
      "  [-8.14541217e-01 -8.28089415e-01 -4.17221644e-01 -5.45041711e-01\n",
      "   -7.19892768e-01 -1.04532048e+00]\n",
      "  [ 5.84714832e-01  1.06600330e+00  2.49399960e-01  2.29184301e-01\n",
      "    1.74695251e-01 -1.72472354e-01]\n",
      "  [-8.42980042e-01 -1.43791933e-01  3.96831562e-04  6.89270118e-02\n",
      "   -2.70137685e-02 -2.89067740e-01]]\n",
      "\n",
      " [[-3.68952256e-01  1.33000222e-02  1.23952295e-01  8.89258926e-02\n",
      "    2.17665605e-01  5.65114450e-01]\n",
      "  [ 4.85597798e-01 -5.50270811e-01 -2.59178332e-02  2.93380524e-02\n",
      "    7.52100827e-02 -7.09008382e-02]\n",
      "  [-4.66607536e-01  3.93897176e-01  1.44346513e-01  1.41550886e-01\n",
      "    2.94432476e-01  4.17691250e-01]\n",
      "  [ 1.03761291e+00  2.00469872e+00  1.07016378e+00  8.69720647e-01\n",
      "    9.01744763e-01  1.20176238e+00]\n",
      "  [-7.93733482e-01 -1.51714485e-02  5.73027551e-02  8.32533148e-02\n",
      "    9.83426710e-02  1.18355645e-01]\n",
      "  [-5.94871025e-01 -2.14522118e-01  3.11768320e-01  7.05366409e-02\n",
      "    2.73974372e-02 -3.30342694e-01]\n",
      "  [-2.76346387e-01  4.26239213e-01  2.21694811e-01  8.95601801e-02\n",
      "    2.12808018e-01 -2.85987826e-01]\n",
      "  [ 1.72962757e-01  1.07742305e-01  4.10970946e-01  3.54067825e-01\n",
      "    4.02695003e-01  7.92520265e-01]\n",
      "  [ 4.40609228e-01 -3.34930222e-01 -8.45417577e-02 -6.15843291e-02\n",
      "   -1.73354725e-01 -6.47738334e-02]\n",
      "  [-2.19190831e-01  4.10625969e-02  4.58384282e-02 -1.09915327e-02\n",
      "   -5.31781101e-02 -3.79257565e-03]\n",
      "  [ 3.23819627e-01  4.56073592e-01  3.63809643e-02 -6.59230485e-03\n",
      "    6.46695439e-02  5.25902552e-01]]\n",
      "\n",
      " [[-8.48205288e-02  3.28604216e-01  8.09409547e-02  1.21163377e-01\n",
      "    1.37806054e-01  1.72919387e-01]\n",
      "  [-5.16838037e-01 -5.37350761e-02  6.18559785e-03  3.81289307e-02\n",
      "    5.29818489e-02 -1.16216155e-01]\n",
      "  [ 1.61396857e-02  1.34365534e+00  2.65544975e-01  1.57220047e-01\n",
      "    1.67888385e-01  1.77171788e-01]\n",
      "  [-7.93733482e-01 -1.51714485e-02  5.73027551e-02  8.32533148e-02\n",
      "    9.83426710e-02  1.18355645e-01]\n",
      "  [ 2.09923038e+00  3.77478345e+00  1.19023554e+00  6.91753066e-01\n",
      "    5.01252197e-01  5.12176612e-02]\n",
      "  [ 2.13841092e-01  5.71409640e-01  3.71662898e-02 -6.03998653e-02\n",
      "   -1.76303105e-01  5.18541815e-02]\n",
      "  [-9.40948060e-02  2.08769743e-01  6.09448642e-02  6.71051242e-03\n",
      "   -1.63259134e-01 -5.77217375e-02]\n",
      "  [-6.78375223e-01  6.35347791e-01  9.52245173e-02  1.91614366e-01\n",
      "    2.67443730e-01  1.45694432e-01]\n",
      "  [-4.21478441e-01 -1.29992844e+00 -2.90896766e-01 -2.04448777e-01\n",
      "   -1.21033566e-01 -1.60695195e-01]\n",
      "  [ 1.14583216e-01  2.63382476e+00  5.01714726e-01  2.04852878e-01\n",
      "    1.00761329e-01 -7.15485597e-02]\n",
      "  [-3.44640519e-01 -3.42974994e-01 -1.15506942e-01 -1.45948427e-01\n",
      "   -1.42433281e-01  2.73190964e-02]]\n",
      "\n",
      " [[ 2.40726415e-01  2.61229272e-01 -1.00867645e-01 -2.22244297e-01\n",
      "   -1.19563922e-01 -2.40733593e-01]\n",
      "  [-9.63905420e-01 -7.28286927e-02 -3.71377780e-02 -1.05560050e-02\n",
      "   -4.75370240e-02 -2.75737531e-02]\n",
      "  [ 3.15914237e-01  3.90021776e-01  3.39372062e-02 -1.68767155e-01\n",
      "   -1.75166636e-02 -3.54223652e-01]\n",
      "  [-5.94871025e-01 -2.14522118e-01  3.11768320e-01  7.05366409e-02\n",
      "    2.73974372e-02 -3.30342694e-01]\n",
      "  [ 2.13841092e-01  5.71409640e-01  3.71662898e-02 -6.03998653e-02\n",
      "   -1.76303105e-01  5.18541815e-02]\n",
      "  [ 9.84201495e-01  9.13841174e-01  1.10760113e+00  8.67340897e-01\n",
      "    9.64913768e-01  1.47745179e+00]\n",
      "  [ 4.09308529e-01  4.95053198e-01  8.31059520e-01  4.53808804e-01\n",
      "    6.36975618e-01  5.98038847e-01]\n",
      "  [-2.89415214e-02  2.01764589e-01  6.34434329e-02 -1.67555795e-01\n",
      "   -7.89273552e-02 -6.21801528e-01]\n",
      "  [-1.87095345e-01 -1.47044915e-01 -3.18802076e-02  1.79674610e-01\n",
      "    6.17877584e-02 -2.68431769e-03]\n",
      "  [ 5.55983171e-01  6.67749941e-01  6.02838181e-02  3.78447030e-02\n",
      "    5.29658374e-02 -3.25246620e-01]\n",
      "  [-1.30751742e-01 -2.66501528e-01 -1.04975085e-01  3.99460276e-02\n",
      "   -6.04701440e-02  2.95305781e-01]]\n",
      "\n",
      " [[ 2.28400523e-01  9.52701754e-02 -5.32533888e-02 -1.10038917e-01\n",
      "   -1.48524828e-01 -3.35513278e-01]\n",
      "  [-5.99823265e-01 -1.67672711e-01  9.44219675e-03  1.76520666e-02\n",
      "   -2.91267216e-02  3.35965084e-01]\n",
      "  [ 3.46499997e-01  3.68591424e-01  1.93825843e-01 -2.71784410e-02\n",
      "    3.57462365e-02 -3.41768540e-01]\n",
      "  [-2.76346387e-01  4.26239213e-01  2.21694811e-01  8.95601801e-02\n",
      "    2.12808018e-01 -2.85987826e-01]\n",
      "  [-9.40948060e-02  2.08769743e-01  6.09448642e-02  6.71051242e-03\n",
      "   -1.63259134e-01 -5.77217375e-02]\n",
      "  [ 4.09308529e-01  4.95053198e-01  8.31059520e-01  4.53808804e-01\n",
      "    6.36975618e-01  5.98038847e-01]\n",
      "  [ 2.70989609e-01  8.54694807e-01  1.29825462e+00  5.39603398e-01\n",
      "    9.04009358e-01  5.81051298e-01]\n",
      "  [ 1.61254170e-01  2.33779545e-01  8.08751160e-02 -6.85449387e-03\n",
      "   -1.61053090e-01 -4.81891724e-01]\n",
      "  [-2.23891717e-01 -1.46236414e-01 -1.51205038e-01  1.24440038e-02\n",
      "    1.48955160e-02  2.12019292e-01]\n",
      "  [ 2.24485581e-01  4.97865695e-01  1.41507704e-01  3.87121112e-02\n",
      "   -2.14903922e-02 -6.37218443e-02]\n",
      "  [-1.98926666e-01 -6.05254375e-02 -1.62175083e-01 -8.65935349e-02\n",
      "    7.60713284e-02  2.31651564e-01]]\n",
      "\n",
      " [[ 9.11954585e-01  6.78147596e-01  4.92283383e-01  7.53568596e-01\n",
      "    1.06037424e+00  1.00815156e+00]\n",
      "  [-1.39873695e+00 -5.40198848e-02 -9.65177990e-02 -2.26459862e-02\n",
      "    9.12758417e-02 -4.09803651e-01]\n",
      "  [ 1.13866195e+00  5.00645453e-01  3.24479172e-01  4.09677989e-01\n",
      "    6.12378692e-01  9.18091819e-01]\n",
      "  [ 1.72962757e-01  1.07742305e-01  4.10970946e-01  3.54067825e-01\n",
      "    4.02695003e-01  7.92520265e-01]\n",
      "  [-6.78375223e-01  6.35347791e-01  9.52245173e-02  1.91614366e-01\n",
      "    2.67443730e-01  1.45694432e-01]\n",
      "  [-2.89415214e-02  2.01764589e-01  6.34434329e-02 -1.67555795e-01\n",
      "   -7.89273552e-02 -6.21801528e-01]\n",
      "  [ 1.61254170e-01  2.33779545e-01  8.08751160e-02 -6.85449387e-03\n",
      "   -1.61053090e-01 -4.81891724e-01]\n",
      "  [ 1.24441271e+00  8.13803334e-01  6.96860389e-01  1.09803006e+00\n",
      "    1.42932366e+00  1.21126778e+00]\n",
      "  [-4.63403138e-01 -6.74138814e-01 -2.06747824e-01 -3.73415401e-01\n",
      "   -4.99585533e-01 -7.15886182e-01]\n",
      "  [ 3.49709791e-01  5.99323064e-01  1.31756938e-01  1.99028574e-01\n",
      "    1.97463304e-01  1.00018579e-01]\n",
      "  [-4.64352434e-01 -2.81398705e-01 -1.60525310e-01 -5.04985533e-01\n",
      "   -6.38816484e-01 -2.31063280e-01]]\n",
      "\n",
      " [[-5.05576913e-01 -7.95904753e-01 -5.59135572e-01 -7.45055153e-01\n",
      "   -8.20020120e-01 -1.12715427e+00]\n",
      "  [ 1.20197012e+00  4.48815438e-01  1.33728109e-01  2.37989632e-01\n",
      "    2.43645634e-01  8.08581851e-01]\n",
      "  [-8.14541217e-01 -8.28089415e-01 -4.17221644e-01 -5.45041711e-01\n",
      "   -7.19892768e-01 -1.04532048e+00]\n",
      "  [ 4.40609228e-01 -3.34930222e-01 -8.45417577e-02 -6.15843291e-02\n",
      "   -1.73354725e-01 -6.47738334e-02]\n",
      "  [-4.21478441e-01 -1.29992844e+00 -2.90896766e-01 -2.04448777e-01\n",
      "   -1.21033566e-01 -1.60695195e-01]\n",
      "  [-1.87095345e-01 -1.47044915e-01 -3.18802076e-02  1.79674610e-01\n",
      "    6.17877584e-02 -2.68431769e-03]\n",
      "  [-2.23891717e-01 -1.46236414e-01 -1.51205038e-01  1.24440038e-02\n",
      "    1.48955160e-02  2.12019292e-01]\n",
      "  [-4.63403138e-01 -6.74138814e-01 -2.06747824e-01 -3.73415401e-01\n",
      "   -4.99585533e-01 -7.15886182e-01]\n",
      "  [ 8.50032599e-01  1.57121431e+00  9.61470312e-01  1.00729342e+00\n",
      "    8.89795227e-01  1.46509337e+00]\n",
      "  [-2.12436540e-01 -1.17134442e+00 -2.04569889e-01 -1.42866876e-01\n",
      "   -5.49576243e-02  1.36716443e-01]\n",
      "  [ 6.91911705e-01  6.07444783e-01  1.47206679e-01  1.86357787e-01\n",
      "    2.50687167e-01  7.80462648e-01]]\n",
      "\n",
      " [[ 4.51643234e-01  3.52655350e-01  7.89592317e-02  1.87817554e-01\n",
      "    1.61718701e-01 -2.99828331e-01]\n",
      "  [-1.11696382e+00 -3.38776317e-01 -1.70736139e-01 -1.63258887e-01\n",
      "   -1.64933321e-01 -2.51043868e-02]\n",
      "  [ 5.84714832e-01  1.06600330e+00  2.49399960e-01  2.29184301e-01\n",
      "    1.74695251e-01 -1.72472354e-01]\n",
      "  [-2.19190831e-01  4.10625969e-02  4.58384282e-02 -1.09915327e-02\n",
      "   -5.31781101e-02 -3.79257565e-03]\n",
      "  [ 1.14583216e-01  2.63382476e+00  5.01714726e-01  2.04852878e-01\n",
      "    1.00761329e-01 -7.15485597e-02]\n",
      "  [ 5.55983171e-01  6.67749941e-01  6.02838181e-02  3.78447030e-02\n",
      "    5.29658374e-02 -3.25246620e-01]\n",
      "  [ 2.24485581e-01  4.97865695e-01  1.41507704e-01  3.87121112e-02\n",
      "   -2.14903922e-02 -6.37218443e-02]\n",
      "  [ 3.49709791e-01  5.99323064e-01  1.31756938e-01  1.99028574e-01\n",
      "    1.97463304e-01  1.00018579e-01]\n",
      "  [-2.12436540e-01 -1.17134442e+00 -2.04569889e-01 -1.42866876e-01\n",
      "   -5.49576243e-02  1.36716443e-01]\n",
      "  [ 5.48231020e-01  2.70581663e+00  1.02784032e+00  8.34780510e-01\n",
      "    5.89661545e-01  5.62569370e-01]\n",
      "  [-2.56117756e-01 -2.76308204e-01  1.07947461e-02 -2.84207345e-02\n",
      "    1.46736287e-02 -2.91863329e-01]]\n",
      "\n",
      " [[-5.28482216e-01 -3.45468939e-01  1.26994275e-02 -1.06422230e-01\n",
      "   -3.56420878e-01 -2.91143570e-01]\n",
      "  [ 1.13427852e+00  4.45427967e-02 -1.28405992e-02 -8.35837650e-02\n",
      "   -1.75991551e-02  5.74376952e-01]\n",
      "  [-8.42980042e-01 -1.43791933e-01  3.96831562e-04  6.89270118e-02\n",
      "   -2.70137685e-02 -2.89067740e-01]\n",
      "  [ 3.23819627e-01  4.56073592e-01  3.63809643e-02 -6.59230485e-03\n",
      "    6.46695439e-02  5.25902552e-01]\n",
      "  [-3.44640519e-01 -3.42974994e-01 -1.15506942e-01 -1.45948427e-01\n",
      "   -1.42433281e-01  2.73190964e-02]\n",
      "  [-1.30751742e-01 -2.66501528e-01 -1.04975085e-01  3.99460276e-02\n",
      "   -6.04701440e-02  2.95305781e-01]\n",
      "  [-1.98926666e-01 -6.05254375e-02 -1.62175083e-01 -8.65935349e-02\n",
      "    7.60713284e-02  2.31651564e-01]\n",
      "  [-4.64352434e-01 -2.81398705e-01 -1.60525310e-01 -5.04985533e-01\n",
      "   -6.38816484e-01 -2.31063280e-01]\n",
      "  [ 6.91911705e-01  6.07444783e-01  1.47206679e-01  1.86357787e-01\n",
      "    2.50687167e-01  7.80462648e-01]\n",
      "  [-2.56117756e-01 -2.76308204e-01  1.07947461e-02 -2.84207345e-02\n",
      "    1.46736287e-02 -2.91863329e-01]\n",
      "  [ 6.70883614e-01  7.94753061e-01  4.65079806e-01  9.29696945e-01\n",
      "    8.93927708e-01  1.18909113e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# instantiate the classifier and train it\n",
    "qda_clf = QDAClassifier()\n",
    "qda_clf.fit(X_train, y_train)\n",
    "\n",
    "assert qda_clf.__dict__.keys(), (\"`fit` method not implemented yet or not \"\n",
    "\"creating the class attributes.\")\n",
    "print(\"Classifier attributes:\")\n",
    "for attr, value in qda_clf.__dict__.items():\n",
    "    shape = f\", shape {value.shape}\" if hasattr(value, \"shape\") else \"\"\n",
    "    print(f\"  * {attr}{shape}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "\n",
    "Implement the predict_proba method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (1119, 11)\n",
      "cov (11, 11)\n",
      "mean (11,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Array 'mean' must be a vector of length 12309.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m qda_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# predict the class probabilities for the training data\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43mqda_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m probs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`predict_proba` method not implemented yet or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot returning a valid array.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m probs\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mlen\u001b[39m(X_train), \u001b[38;5;241m6\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`predict_proba` output should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shape (num_examples, num_classes).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 58\u001b[0m, in \u001b[0;36mQDAClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcov\u001b[39m\u001b[38;5;124m'\u001b[39m,cov\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,mean\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 58\u001b[0m     likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     probs[:, idx] \u001b[38;5;241m=\u001b[39m likelihood \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriors[idx]\n\u001b[0;32m     61\u001b[0m probs_sum \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ulloa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:397\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.__call__\u001b[1;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a frozen multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    See `multivariate_normal_frozen` for more information.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultivariate_normal_frozen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ulloa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:903\u001b[0m, in \u001b[0;36mmultivariate_normal_frozen.__init__\u001b[1;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a frozen multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    899\u001b[0m \n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m \u001b[38;5;66;03m# numpy/numpydoc#87  # noqa: E501\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist \u001b[38;5;241m=\u001b[39m multivariate_normal_gen(seed)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_object \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 903\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_singular \u001b[38;5;241m=\u001b[39m allow_singular \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_object\u001b[38;5;241m.\u001b[39m_allow_singular\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m maxpts:\n",
      "File \u001b[1;32mc:\\Users\\ulloa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:414\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters\u001b[1;34m(self, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_parameters_Covariance(mean, cov)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Before `Covariance` classes were introduced,\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m# `multivariate_normal` accepted plain arrays as `cov` and used the\u001b[39;00m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;66;03m# following input validation. To avoid disturbing the behavior of\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# `multivariate_normal` when plain arrays are used, we use the\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;66;03m# original input validation here.\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m     dim, mean, cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters_psd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;66;03m# After input validation, some methods then processed the arrays\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# with a `_PSD` object and used that to perform computation.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;66;03m# To avoid branching statements in each method depending on whether\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;66;03m# `cov` is an array or `Covariance` object, we always process the\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;66;03m# array with `_PSD`, and then use wrapper that satisfies the\u001b[39;00m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;66;03m# `Covariance` interface, `CovViaPSD`.\u001b[39;00m\n\u001b[0;32m    421\u001b[0m     psd \u001b[38;5;241m=\u001b[39m _PSD(cov, allow_singular\u001b[38;5;241m=\u001b[39mallow_singular)\n",
      "File \u001b[1;32mc:\\Users\\ulloa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:471\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters_psd\u001b[1;34m(self, dim, mean, cov)\u001b[0m\n\u001b[0;32m    468\u001b[0m     cov \u001b[38;5;241m=\u001b[39m cov\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a vector of length \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    472\u001b[0m                      dim)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cov\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    474\u001b[0m     cov \u001b[38;5;241m=\u001b[39m cov \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(dim)\n",
      "\u001b[1;31mValueError\u001b[0m: Array 'mean' must be a vector of length 12309."
     ]
    }
   ],
   "source": [
    "# instantiate the classifier\n",
    "# (we need to do this again because you probably changed the code of QDAClassifier\n",
    "# after you ran the previous cell)\n",
    "qda_clf = QDAClassifier()\n",
    "qda_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the class probabilities for the training data\n",
    "probs = qda_clf.predict_proba(X_train)\n",
    "\n",
    "assert probs is not None, (\"`predict_proba` method not implemented yet or \"\n",
    "\"not returning a valid array.\")\n",
    "assert probs.shape == (len(X_train), 6), (\"`predict_proba` output should \"\n",
    "\"have shape (num_examples, num_classes).\")\n",
    "assert np.all((probs >= 0) * (probs <= 1)), (\"`predict_proba` output should be \"\n",
    "\"probabilities.\")\n",
    "assert np.allclose(probs.sum(axis=1), 1), (\"`predict_proba` output should be a \"\n",
    "\"(proper) probability distribution.\")\n",
    "print(\"Your `predict_proba` looks good! 🚀\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 \n",
    "\n",
    "Write your predict method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "# (we need to do this again because you probably changed the code of QDAClassifier\n",
    "# after you ran the previous cell)\n",
    "qda_clf = QDAClassifier()\n",
    "qda_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the class labels for the training data\n",
    "y_train_pred = qda_clf.predict(X_train)\n",
    "assert y_train_pred is not None, (\"`predict` method not implemented yet or not returning \"\n",
    "\"any predictions.\")\n",
    "assert len(y_train_pred) == len(X_train), (\"You should have one predicted \"\n",
    "\"label for each input example.\")\n",
    "print(\"Your classifier predicted:\")\n",
    "for j in range(6):\n",
    "    print(f\"  * {(y_train_pred == j).sum()} training examples in class {j}.\")\n",
    "print()\n",
    "\n",
    "# predict the class labels for the test data\n",
    "y_test_pred = qda_clf.predict(X_test)\n",
    "assert y_test_pred is not None, (\"`predict` method not implemented yet or not returning \"\n",
    "\"any predictions.\")\n",
    "assert len(y_test_pred) == len(X_test), (\"You should have one predicted \"\n",
    "\"label for each input example.\")\n",
    "print(\"Your classifier predicted:\")\n",
    "for j in range(6):\n",
    "    print(f\"  * {(y_test_pred == j).sum()} test examples in class {j}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5\n",
    "Using the compute_accuracy that you have already defined, compute the performance of the QDA on the given data. Compare the results with the ones obtained with LDA and define which one would you deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the training accuracy\n",
    "train_accuracy = compute_accuracy(y_train, y_train_pred)\n",
    "assert train_accuracy is not None, (\"`compute_accuracy` not implemented yet or \"\n",
    "\"not returning a valid float.\")\n",
    "print(f\"Training accuracy: {train_accuracy:.3f}\")\n",
    "\n",
    "# compute the test accuracy\n",
    "test_accuracy = compute_accuracy(y_test, y_test_pred)\n",
    "assert test_accuracy is not None, (\"`compute_accuracy` not implemented yet or \"\n",
    "\"not returning a valid float.\")\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
